# -*- coding: utf-8 -*-
"""Google coral board power.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18UAmqs2SdP1rtmqzcVmESTnGB1693DgG
"""

import numpy as np
import time
import sys
import csv
import os
from datetime import datetime
from pycoral.utils.edgetpu import make_interpreter, list_edge_tpus

# For power measurement
try:
    import psutil
except ImportError:
    print("Installing psutil for power monitoring...")
    import subprocess
    subprocess.check_call([sys.executable, "-m", "pip", "install", "psutil"])
    import psutil

# Load data and model
try:
    X_test = np.load('selected_features.npy')
    y_test = np.load('selected_labels.npy')
except Exception as e:
    print(f"Error loading files: {e}")
    sys.exit(1)

# Check for Edge TPU
available_tpus = list_edge_tpus()
if not available_tpus:
    print("No Edge TPU detected. Running on CPU only.")
    interpreter = make_interpreter('model_int8.tflite')
else:
    print(f"Edge TPU detected: {available_tpus[0]}")
    interpreter = make_interpreter('model_int8_edgetpu.tflite')

interpreter.allocate_tensors()

# Get model details
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Preprocessing
if X_test.shape[1:] == (18, 640):
    X_test = np.ascontiguousarray(X_test.transpose(0, 2, 1))

input_quant = input_details[0]['quantization']
if input_details[0]['dtype'] == np.int8:
    scale, zero_point = input_quant[0], input_quant[1]
    X_test = np.clip(np.round(X_test/scale + zero_point), -128, 127).astype(np.int8)

# Prepare CSV file
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
csv_filename = f"seizure_detection_results_{timestamp}.csv"
csv_headers = ['Sample_ID', 'True_Label', 'Predicted_Label', 'Confidence_Score',
               'Inference_Time_ms', 'Power_Usage_W', 'Status']

with open(csv_filename, 'w', newline='') as csvfile:
    csv_writer = csv.writer(csvfile)
    csv_writer.writerow(csv_headers)

    # Inference loop
    correct = 0
    total_time = 0
    total_power = 0

    print("\nRunning seizure detection:\n")
    for idx in range(len(X_test)):
        # Measure power before inference
        power_start = psutil.cpu_percent(interval=0.1)

        input_data = np.expand_dims(X_test[idx], axis=0)
        interpreter.set_tensor(input_details[0]['index'], input_data)

        # Run inference and measure time
        start_time = time.monotonic()
        interpreter.invoke()
        inference_time = (time.monotonic() - start_time) * 1000
        total_time += inference_time

        # Measure power after inference
        power_end = psutil.cpu_percent(interval=0.1)
        power_usage = (power_start + power_end) / 2  # Average CPU usage during inference
        total_power += power_usage

        # Get output and process
        output = interpreter.get_tensor(output_details[0]['index'])

        # Dequantize if needed
        if output_details[0]['dtype'] == np.int8:
            output_scale, output_zero = output_details[0]['quantization']
            output = (output.astype(np.float32) - output_zero) * output_scale

        # Get prediction and confidence
        softmax_output = np.exp(output) / np.sum(np.exp(output), axis=1, keepdims=True)
        confidence = np.max(softmax_output)
        pred = np.argmax(output)
        true_label = y_test[idx]

        # Determine status
        status = "SEIZURE DETECTED" if pred == 1 else "SEIZURE NOT DETECTED"
        print(f"Sample {idx+1}: {status} | Confidence: {confidence:.4f} | {inference_time:.2f}ms | CPU: {power_usage:.2f}%")

        # Write to CSV
        csv_writer.writerow([
            idx+1,
            true_label,
            pred,
            f"{confidence:.4f}",
            f"{inference_time:.2f}",
            f"{power_usage:.2f}",
            status
        ])

        if pred == true_label:
            correct += 1

# Final results
accuracy = (correct / len(y_test)) * 100
avg_time = total_time / len(y_test)
avg_power = total_power / len(y_test)

# Estimate power in Watts (very rough approximation)
# Assuming a typical system power usage of 15W at 100% CPU
est_watts = (avg_power / 100) * 15

print("\n-----------------------------")
print(f" Final Accuracy: {accuracy:.2f}%")
print(f" Average Inference Time: {avg_time:.2f}ms")
print(f" Average CPU Usage: {avg_power:.2f}%")
print(f" Estimated Power Consumption: {est_watts:.2f}W")
print("-----------------------------")
print(f"\nResults saved to: {csv_filename}")
print(f"Total samples processed: {len(y_test)}")

# Function to convert the CSV to human-readable format
def create_summary_report(csv_filename):
    report_filename = csv_filename.replace('.csv', '_summary.txt')

    with open(csv_filename, 'r') as csvfile, open(report_filename, 'w') as reportfile:
        reader = csv.DictReader(csvfile)
        rows = list(reader)

        reportfile.write("SEIZURE DETECTION SUMMARY REPORT\n")
        reportfile.write("==============================\n\n")
        reportfile.write(f"Date/Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        reportfile.write(f"Total Samples: {len(rows)}\n")

        # Count detected seizures
        seizures_detected = sum(1 for row in rows if row['Status'] == 'SEIZURE DETECTED')
        reportfile.write(f"Seizures Detected: {seizures_detected}\n")
        reportfile.write(f"No Seizures Detected: {len(rows) - seizures_detected}\n\n")

        # Performance metrics
        avg_time = sum(float(row['Inference_Time_ms']) for row in rows) / len(rows)
        avg_power = sum(float(row['Power_Usage_W']) for row in rows) / len(rows)
        reportfile.write(f"Average Inference Time: {avg_time:.2f}ms\n")
        reportfile.write(f"Average Power Usage: {avg_power:.2f}%\n")
        reportfile.write(f"Estimated Power Consumption: {(avg_power / 100) * 15:.2f}W\n\n")

        reportfile.write("SAMPLE DETAILS\n")
        reportfile.write("--------------\n")
        for i, row in enumerate(rows[:10]):  # Show first 10 samples
            reportfile.write(f"Sample {row['Sample_ID']}: {row['Status']} (Confidence: {row['Confidence_Score']})\n")

        if len(rows) > 10:
            reportfile.write(f"... and {len(rows) - 10} more samples\n")

    print(f"Summary report created: {report_filename}")

# Create summary report
create_summary_report(csv_filename)